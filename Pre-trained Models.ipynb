{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Inputs of Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape (513, 693, 3)\n",
      "preprocessing shape image (3, 256, 456)\n"
     ]
    }
   ],
   "source": [
    "# OpenCV read in BGR format, the loaded images are similar to a numpy array\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "POSE_IMAGE = cv2.imread('images/img1.jpg')\n",
    "\n",
    "# TODO: shape -> [1x3x256x456] - format [BxCxHxW]\n",
    "def pose_estimation(input_image):\n",
    "    image = np.copy(input_image)\n",
    "    dim = (456, 256) \n",
    "    print(\"original shape {}\".format(image.shape))\n",
    "    image = cv2.resize(image, dim)\n",
    "    image = image.transpose(2, 0, 1)\n",
    "    print('preprocessing shape image {}'.format(image.shape))\n",
    "    image = image.reshape(1, 3, 256, 456)\n",
    "    return image\n",
    "    \n",
    "def text_detection(input_image):\n",
    "    '''\n",
    "    using cv2.resize()\n",
    "    '''\n",
    "    preprocessed_image = np.copy(input_image)\n",
    "\n",
    "    preprocessed_image = cv2.resize(preprocessed_image, (1280, 768))\n",
    "    preprocessed_image = preprocessed_image.transpose((2,0,1))\n",
    "    preprocessed_image = preprocessed_image.reshape(1, 3, 768, 1280)\n",
    "    return preprocessed_image\n",
    "    \n",
    "def main():\n",
    "    #choose model\n",
    "    img = pose_estimation(POSE_IMAGE)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 2 types of datasets: https://software.intel.com/en-us/openvino-toolkit/documentation/pretrained-models\n",
    "# Public Model Set = must be run through the Model Optimizer, have a original models to train an fine-tuning\n",
    "# Free Model Set = converted to Intermediate Rep formate, don not have original model, to get with Model Downloader\n",
    "\n",
    "################### Using Model Downloader tool ######################\n",
    "# Human Pose Estimation: All precision levels\n",
    "\n",
    "#cd /opt/intel/openvino/deployment_tools/tools/model_downloader\n",
    "#sudo ./downloader.py —name vehicle-attributes-recognition-barrier-0039 —precisions INT8 -o /home/workspace\n",
    "# sudo ./downloader.py --name text-detection-0004 --precisions FP16 -o /home/workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_pose(output, input_shape):\n",
    "    '''\n",
    "    Handles the output of the Pose Estimation model.\n",
    "    Returns ONLY the keypoint heatmaps, and not the Part Affinity Fields.\n",
    "    '''\n",
    "    # TODO 1: Extract only the second blob output (keypoint heatmaps)\n",
    "    heatmaps = output['Mconv7_stage2_L2']\n",
    "    # TODO 2: Resize the heatmap back to the size of the input\n",
    "    # Create an empty array to handle the output map\n",
    "    out_heatmap = np.zeros([heatmaps.shape[1], input_shape[0], input_shape[1]])\n",
    "    # Iterate through and re-size each heatmap\n",
    "    for h in range(len(heatmaps[0])):\n",
    "        out_heatmap[h] = cv2.resize(heatmaps[0][h], input_shape[0:2][::-1])\n",
    "\n",
    "    return out_heatmap\n",
    "\n",
    "\n",
    "def handle_text(output, input_shape):\n",
    "    '''\n",
    "    Handles the output of the Text Detection model.\n",
    "    Returns ONLY the text/no text classification of each pixel,\n",
    "        and not the linkage between pixels and their neighbors.\n",
    "    '''\n",
    "    # TODO 1: Extract only the first blob output (text/no text classification)\n",
    "    text_classes = output['model/segm_logits/add']\n",
    "    # TODO 2: Resize this output back to the size of the input\n",
    "    out_text = np.empty([text_classes.shape[1], input_shape[0], input_shape[1]])\n",
    "    for t in range(len(text_classes[0])):\n",
    "        out_text[t] = cv2.resize(text_classes[0][t], input_shape[0:2][::-1])\n",
    "\n",
    "    return out_text\n",
    "\n",
    "\n",
    "def handle_car(output, input_shape):\n",
    "    '''\n",
    "    Handles the output of the Car Metadata model.\n",
    "    Returns two integers: the argmax of each softmax output.\n",
    "    The first is for color, and the second for type.\n",
    "    '''\n",
    "    # Get rid of unnecessary dimensions\n",
    "    color = output['color'].flatten()\n",
    "    car_type = output['type'].flatten()\n",
    "    # TODO 1: Get the argmax of the \"color\" output\n",
    "    color_pred = np.argmax(color)\n",
    "    # TODO 2: Get the argmax of the \"type\" output\n",
    "    type_pred = np.argmax(car_type)\n",
    "\n",
    "    return color_pred, type_pred\n",
    "\n",
    "\n",
    "def handle_output(model_type):\n",
    "    '''\n",
    "    Returns the related function to handle an output,\n",
    "        based on the model_type being used.\n",
    "    '''\n",
    "    if model_type == \"POSE\":\n",
    "        return handle_pose\n",
    "    elif model_type == \"TEXT\":\n",
    "        return handle_text\n",
    "    elif model_type == \"CAR_META\":\n",
    "        return handle_car\n",
    "    else:\n",
    "        return None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
